---
output: github_document

  
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# CarefullyCausal

<!-- badges: start -->
<!-- badges: end -->


The goal of CarefullyCausal is to provide the user a practical guide when doing causal analyses. Particularly, CarefullyCausal provides the user the estimand, a table of causal estimates, a discussion on the causal assumptions, relevant diagnostics and interpretations/explanations. The key aspects of a causal analyses are printed and discussed in detail to help the user evaluate whether the estimated effects can be interpreted as being causal. Currently, CarefullyCausal can be used in a setting with a fixed-exposure, meaning that the exposure does not vary over time.\

Some key features:\

* **Setting**: Fixed-exposure
* **Outcome of interest**: can be dichotomous or continuous
* **Exposure of interest**: can be dichotomous, multi-value (max 4 levels) or continuous
* **Effect measures**: can be in log(odds), risk ratio or odds ratio



## Installation

You can install the development version of CarefullyCausal as follows:
```{r install, eval=FALSE}
# To download R packages from Github or other sources we need the "devtools" package
install.packages("devtools")
library("devtools")

# Now we can download the CarefullyCausal package
install_github("mauricekorf/CarefullyCausal")
library(CarefullyCausal)
```


## Example

To develop some intuition with the CarefullyCausal function and to highlight some important features, an example is step-by-step illustrated using the NHEFS^[National Health and Nutrition Examination Survey Data I Epidemiologic Follow-up Study, https://wwwn.cdc.gov/nchs/nhanes/nhefs/] data set.


### Research Question

Suppose that we are interested in the causal relation between quitting smoking and weight change (in Kilograms). Specifically,we would like to know the effect of quitting smoking on someone's weight change during the period 1971-1982 where the first measurement took place in 1971 and the second one in 1982. Suppose further that, in order to evaluate this causal relation, we assume that there are some important confounders we need to adjust for, which includes:\
sex, race, age, education level, smoke intensity (number of cigarettes per day), how long someone has been smoking ( in years), start weight (in Kilograms), how much someone exercises (**0:** much exercise, **1:** moderate exercise, **2:** no exercise) and how active a person is on a usual day (**0:** very active, **1:** moderately active, **2:** inactive)

<br>
Given that we assume that these are the only confounders and that no collider bias or selection bias is induced, we would obtain the following simple Directed Acyclic Graph (DAG):
<p align='center'>
```{r RQ, eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=10, out.width='60%', fig.align='center'}
library(ggdag)
library(ggplot2)
library(causaldata)
library(kableExtra)
library(CarefullyCausal)

# Load in the data, we will use the complete cases variant
df = nhefs_complete

# Make the coordination of the different nodes
# https://lfoswald.github.io/2021-spring-stats2/materials/session-3/03-online-tutorial/
coord_dag <- list(
  x = c(qsmk = 0, wt82_71 = 3, sex = 1.5, race = 1.5, education = 1.5, smokeintensity = 1.5, smokeyrs = 1.5, wt71 = 1.5, exercise = 1.5, active = 1.5, age = 1.5 ),
  y = c(qsmk = 0, wt82_71 = 0, sex = 1, race = 1.5, education = 2, smokeintensity = 2.5, smokeyrs = -1, wt71 = -1.5, exercise = -2, active = -2.5, age = -3)
)
# Create the DAG structure
our_dag <- ggdag::dagify(wt82_71 ~ qsmk,
                         wt82_71 ~ sex + race + education + smokeintensity + smokeyrs + wt71 + exercise + active + age,
                         qsmk ~ sex + race + education + smokeintensity + smokeyrs + wt71 +exercise + active + age,
                         coords = coord_dag,
                         labels = c("wt82_71" = "Weight\n change",
                                    "qsmk" = "Quit smoke",
                                    "race" = "race",
                                    "sex" = "sex",
                                    "education" = "education",
                                    "smokeintensity" = "number cigarettes",
                                    "smokeyrs" = "years smoking",
                                    "wt71" = "start weight",
                                    "exercise" = "exercise",
                                    "active" = "active",
                                    "age" = "age"))
# Plot the DAG
ggdag(our_dag, text = FALSE, use_labels = "label") + theme_void()

```
</p>
<center>
<i>Figure 1: </i>The selected variables are for illustration purposes only. The DAG shows by no means the true causal structure
</center>
<br>



### Data

In order to answer our research question, we will use a subset of the NHEFS data set from Hernán MA & Robins JM (2020) in the *Causal inference: What if* book^[Hernán MA, Robins JM (2020). Causal Inference: What If. Boca Raton: Chapman & Hall/CRC,https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/]. To conveniently import this data set we will use the package *causaldata*.

```{r download data, eval=FALSE}
# Download the required package, containing various (causal) data sets
install.packages("causaldata")
library(causaldata)

# Load in the data, we will use the complete cases variant
df = nhefs_complete
```
<br>


We will now select the variables that we deemed to be relevant, as shown in Figure 1 (DAG). We show the first six rows of the data set below, to get an idea of the data set.
```{r select variables data, eval=TRUE}
# Select variables
df = nhefs_complete[,c("wt82_71","qsmk","race","sex","education","smokeintensity", "smokeyrs","wt71","exercise","active", "age")]
```

```{r show variables data, eval=TRUE, echo=FALSE}
# Get an idea of the data (first 6 rows)
knitr::kable(head(df))
```
<br>

To further inspect the variable coding and the corresponding definition, a table is created below which also includes the class of the variable.
<center>
```{r explain variables data, eval=TRUE, echo=FALSE, fig.align='center', out.width="60%"}
# Get an idea how the variables are coded and what type it is
variables <- setNames(stack(sapply(df, class))[2:1], c('variable', 'class'))
description <- c("The weight change between 1971 and 1982 in Kg ",
                 "Quit smoking during 1971-1982, 1: yes, 0: no",
                 "1: black or other, 0: white, ",
                 "1: female, 0: male",
                 "1: 8th grade, 2: HS dropout, 3: HS, 4: college dropout, 5: college or higher",
                 "Number of cigarettes smoked per day in 1971",
                 "Years of smoking",
                 "Start weight (Kg) in 1971",
                 "In recreation in 1971 how mu h exercising, 0: much, 1: moderate, 2: little or none",
                 "On usual day how active in 1971, 0: very active, 1: moderately active, 2: inactive",
                 "Age in 1971")

variables = cbind(variables,description)
knitr::kable(variables)
```
</center>
<br>


### Analysis (Applying CarefullyCausal)

We will now shift our focus to actually using the CarefullyCausal function. The minimal call requires us to specify the following arguments: `formula, data, family` and `exposure`. Note that you can always consult the help file within R to see the documentation of CarefullyCausal and to learn about all available arguments including an explanation. You can access this by simply typing in *CarefullyCausal* in the help tab in R. Nonetheless, we summarise the key arguments we need for the minimal call.


* `Formula`, this has the same form as for example when using *glm* which is $y\sim x + w$. Here $y$ denotes the outcome of interest variable, $x$ denotes the exposure and $w$ is a covariate we want to adjust for. The $y$ variable should be a numeric vector, $x$ should be a factor when exposure is discrete and adjustment variables $\boldsymbol{w}$ can be any class 
* `Data`, specify the data frame (data set should be a data frame)
* `Family`, this is the same as in *glm* where it describes the error distribution and link function. Here we have two choices: `"gaussian"` or `"binomial"`. This depends on the nature of the outcome of interest. In our example the outcome is continuous and thus we use the `"gaussian"` argument (default setting)
* `Exposure`, we explicitly define our exposure variable as a character string. In this example, it will be `"qsmk"`


```{r analysis, eval=TRUE, fig.show='hide', warning=FALSE, message=FALSE}
# Transform exposure in a factor variable and transform into dataframe
df$qsmk = as.factor(df$qsmk) 
df = as.data.frame(df)

# Run the CarefullyCausal function and save it in the object "output"
output <- CarefullyCausal(wt82_71 ~ qsmk + race + sex + education + smokeintensity + smokeyrs + wt71 + exercise
                          + active + age,
                          data = df,
                          exposure = "qsmk",
                          family = "gaussian")
# Print the output
output


```
<br>

The output of the CarefullyCausal function is shown above and can be broadly classified into the sections: estimand,
estimators and assumptions/diagnostics. We go over each part now in more detail.

##### Estimand
The first lines in the output show the *estimand*, which is a precise description of your research question and should be defined before the analyses. Defining the estimand requires the user to think through many aspects, such as the population in which the research question is being asked, the duration and timing of exposure, the definition of the exposure and so on. Printing the estimand in the R output might ideally be considered as redundant, post-analysis, as it can inform us only about basic characteristics. Particularly, the printed estimand can only tell us about basic characteristics of the estimand targeted by the user, including: the exposure variable, outcome variable, adjustment set and counterfactual contrast. Nonetheless, the idea of explicitly showing the estimand might serve as a reminder for the user to think through whether there is any discrepnancy between the actual estimated effect and the question of interest and motivates the user to double-check the pre-analysis part of thinking through the research question and corresponding estimand. In addition, the estimand uses counterfactual notation and therewith emphasizes that we are interested in causal effects without ambiguity. We provide both a conditional and marginal estimand since we provide different estimators and different type of estimands correspond to different estimators. In essence, the idea of the estimand is the same but due to more technical reasons (how the estimators work) we write the estimand in a conditional or marginal way. Important to note is that the marginal estimand is still adjusting for all the variables like shown in the conditional estimand, but we do not write the adjusted variables explicitly in the marginal estimand. To learn more about estimands and its formulation see: ^[Luijken, K., van Eekelen, R., Gardarsdottir, H., Groenwold, R. H., & van Geloven, N. (2023). Tell me what you want, what you really really want: Estimands in observational pharmacoepidemiologic comparative effectiveness and safety studies. Pharmacoepidemiology and Drug Safety.] ^[Goetghebeur, E., le Cessie, S., De Stavola, B., Moodie, E. E., Waernbaum, I., & ” the topic group Causal Inference (TG7) of the STRATOS initiative. (2020). Formulating causal questions and principled statistical answers. Statistics in medicine, 39(30), 4922-4948.] ^[Kahan, B. C., Cro, S., Li, F., & Harhay, M. O. (2023). Eliminating ambiguous treatment effects using estimands. American Journal of Epidemiology, 192(6), 987-994.]
```{r estimand output, eval=FALSE}
#> Estimand: 
#> Conditional 
#> E[wt82_71^qsmk=1|race, sex, education, smokeintensity, smokeyrs, wt71, exercise, active, age]  - E[wt82_71^qsmk=0|race, sex, education, smokeintensity, smokeyrs, wt71, exercise, active, age]
#> 
#> Marginal 
#> E[wt82_71^qsmk=1]  -  E[wt82_71^qsmk=0]
#> *Please see output at $Estimand_interpretation for details 

```
<br>

We can obtain a description of the estimand from the saved output. In this example the CarefullyCausal output was saved in the object named *output*. Hence, we call this specific output object.

```{r estimand explanation output, eval=FALSE}
# Show saved output from $Estimand_interpretation
output$Estimand_interpretation

#> [1] "The estimand shows the average causal effect in the population of interest given the different exposure
#> regimes. More specifically, the effect of receiving exposure level 1 with respect to the reference exposure
#> level 0. When adjusting for a set of covariates (race, sex, education, smokeintensity, smokeyrs, wt71,
#> exercise, active, age) the estimand is displayed in either a conditional or marginal way. Particularly,
#> defining the estimand depends on the approach/model used. For example, outcome regression has a conditional
#> estimand while IPTW has a marginal estimand. The T-standardization approach also has a marginal estimand
#> while for the S-standardization it depends on whether interactions between treatment and covariates are
#> taken into account. When no interactions are considered, then it is the same as outcome regression and
#> thus has a conditional estimand, however when all interactions are considered then it is like
#> T-standardization and thus has a marginal estimand."
```
<br>


##### Estimators
After displaying the estimand, different estimators are shown in a table with corresponding estimates, standard errors, s-values and 95% confidence intervals. The p-values can also be shown by setting `pvalue=TRUE`, but is hidden by default. The S-value is a transformation of the p-value by applying $-log_2(p-value)$. The S-value is continuum and ranges from 0 to infinity, where a p-value of 1 corresponds to a S-value of 0 and a p-value of 0 corresponds to a S-value approaching infinity. Intuitively, the S-value captures the amount of information in the data against the model and quantifies how *suprised* we can be about a specific outome. In other words, a very high S-value implies that we would be suprised by the findings we found, given all background assumptions and test hypotheses. Showing the S-value by default rather than the p-value is motivated by that in practice a lot of studies dichotomize settings based on a single cut-off value (e.g $0.05$) where below that value it is interpreted as *useful* and above it is interpreted as *not useful*. In this way the focus is generally purely on the statistical significance and tends to result in underacknowledgment of the practical significance.^[Rose-Nussbaumer, J. (2021). Statistical Significance vs Clinical Significance—That Is the Question. JAMA ophthalmology, 139(11), 1235-1235.] ^[Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., & Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European journal of epidemiology, 31, 337-350.] ^[14.	Greenland, S. (2019). Valid p-values behave exactly as they should: Some misleading criticisms of p-values and their resolution with s-values. The American Statistician, 73(sup1), 106-114]

CarefullyCausal currently supports five different estimators, as shown below, where key characteristics are listed below:

* *Outcome Regression*: for outcome regression `glm` is implemented. When `family = "gaussian"` linear regression is by default performed and when `family = "binomial"` logistic regression will be implemented.
* *Inverse Probability Treatment Weighting (IPTW)*: Propensity scores are estimated using the `CBPS` package, which are *Covariate Balancing Propensity Scores*^[Fong C, Ratkovic M, Imai K (2022). _CBPS: Covariate Balancing Propensity Score_. R package version0.23, <https://CRAN.R-project.org/package=CBPS>.]. Technical details about how *CBPS* works can be found for binary exposure^[Imai, K., & Ratkovic, M. (2014). Covariate balancing propensity score. Journal of the Royal Statistical Society Series B: Statistical Methodology, 76(1), 243-263.], for multi-value exposure^[Imai, K., & Ratkovic, M. (2015). Robust estimation of inverse probability weights for marginal structural models. Journal of the American Statistical Association, 110(511), 1013-1023.] and for continuous exposure^[Fong, C., Hazlett, C., & Imai, K. (2018). Covariate balancing propensity score for a continuous treatment: Application to the efficacy of political advertisements. The Annals of Applied Statistics, 12(1), 156-177.]. Based on the estimated propensity scores, *non-stabilized* weights (*IP weights*) will be computed. Subsequently, the `svyglm` function from the `survey` package is used to run a weighted glm with the IP weights to get the correct corresponding standard errors. By default `CBPS` is implemented, but the user can also input their own *IP weights* as a vector using the `ip_weights_iptw` argument and offers fully flexibility.
* *S-and-T-standardization*: these two approaches are generally referred within the causal inference literature to the broad approach of *standardization* (G-computation). In CarefullyCausal an explicit distinction is made between different standardization approaches, hence the two different namings. The names are inspired by the machine learning literature where similar ideas are generalized and clear distinctions are made between different approaches and respectively referred to as S-learner and T-learner^[Künzel, S. R., Sekhon, J. S., Bickel, P. J., & Yu, B. (2019). Metalearners for estimating heterogeneous treatment effects using machine learning. Proceedings of the national academy of sciences, 116(10), 4156-4165.]. The S-learner and T-learner can be viewed as two different standardization approaches where the S-learner uses a single model and the T-learner uses two models. Specifically, with the S-learner a single model is fitted on all data and then the counterfactual effects are predicted under all exposure levels using this fitted model. In contrast, the T-learner first splits the data based on the exposure variable and then fits a model per exposure level (subset of data). Each model is then used to predict the counterfactual effects for the entire sample under each exposure level. A clear distinction between slightly different approaches is preferable, but to make a clear link to the causal inference terminology such that it sounds more familiar, we introduced the names S-standardization and T-standardization. When using S-standardization, the user can add interactions between any covariate and the exposure using the `interaction` argument. When no interactions are included it will be equivalent to outcome regression and when all possible interactions are considered between the adjustment set and exposure it is equivalent to T-standardization. Currently, CarefullyCausal only supports `glm`. Bootstrapping is used to obtain standard errors and p-values and the number of iterations are respectively controlled by arguments `boot1` and `boot2`. Moreover, a normal confidence interval or bias-corrected accelerated confidence interval can be computed and specified using the `confidence` argument. Note that these estimators do support continuous exposures.
* *Targeted Maximum Likelihood Estimation (TMLE)*: TMLE is a two-stage estimation procedure. First, there is the g-estimation part which is just like S-standardization where we model the outcome of interest. The default within the TMLE framework is to use the `SuperLearner` function from the `SuperLearner` package. In CarefullyCausal we also integrated `SuperLearner` for this step and the user can specify the algorithm library using the `outcome_SL_library` argument using the exact same format as in the `SuperLearner` function. The default is that the library only includes `c("SL.glm")` and thus implies that simply glm is used. The second stage updates the model from the first stage by incorporating information in the treatment assignment mechanism and is referred to as the targeting step. For this second stage we need to estimate propensity scores and is by default done using `SuperLearner`. Within CarefullyCausal this is also the default option where `ps_method="SL"` and the same algorithm library is used as specified for stage one and thus follows argument `outcome_SL_library`. However, the user can specify a different library specifically for estimating the propensity scores using SuperLearner by using the argument `ps_SL_library`. Besides the option of specifying the propensity score estimation library, the user can also specify a different formula for estimating the propensity scores using argument `ps_formula`. By default, the formula used for estimating the propensity scores will be $exposure \sim input \ covariates$, meaning it uses all the covariates that were input in the initial CarefullyCausal call. However, you can fully customize what variables to include or exclude for estimating the propensity scores, even variables that were initially not input.
Besides using `Superlearner` for this estimation step, you can also use `CBPS` using argument `ps_method="cbps"`. For complete flexibility, you can input your own estimated propensity scores using argument `ps_tmle` and if used it will ignore all of the above arguments. Note, CarefullyCausal implements currently only tmle for dichotomous exposures.

```{r estimator, eval=FALSE}
#> Treatment effect: 
#>                       Estimate Std. Error S-value 95%.CI.lower 95%.CI.upper
#> qsmk1 outcome regression    3.381      0.441  44.858        2.517        4.246
#> qsmk1 IPTW                  3.318      0.494  35.198        2.351        4.286
#> qsmk1 S-standardization     3.381      0.549     Inf        2.194        4.344
#> qsmk1 T-standardization     3.448      0.523     Inf        2.479        4.528
#> qsmk1 TMLE                  3.370      0.494     Inf        2.401        4.339

#> Reference exposure level: 0 


#> Please evaluate whether the difference beteen the lowest estimate: 3.3183 and highest: 3.4482 is of substance, 
#> given the nature of the data. If so, evaluate the different modelling assumptions.

```
<br>

Below the estimates table the reference exposure level is explicitly stated. When having a multi-value exposure then all the contrasts are displayed with respect to the reference exposure level for each estimator. However, when you would like to change the reference exposure level you need to relevel the exposure variable (factor). CarefullyCausal by defaults picks the first level as reference level, which is the default behavior of R aswell, where the reference level can be viewed using argument `level(exposure)`.

The last lines state that you should evaluate whether the difference between the estimates is of substance or not. Important to note is that there is *not* a best model, but that you should fit different estimators to see if they agree and may provide you with a broader context to the estimate. If all the estimates are very similar it does not guarantuee that the estimates are unbiased but at least it provides us with more information than when reporting a single estimate. However, if the estimates are very different (*depends on the data, domain and assumptions*) and this is considered to be practically important, then it should be investigated why. This raises questions such as whether particular modelling assumptions are violated? How these are violated? and if there is a solution? and so on. So, rather than seeing it is about selecting a *best model* it is more to provide you with information that might indicate that further inspection is necessary.

In this example we have a continuous outcome and thus the estimates are interpreted in the units of the outcome variable. When the outcome variable is dichotomous, the default is that the estimates are in terms of log(odds ratio) but you can specify the arguments `result_type="rr"` or `result_type="or"` to get it in terms of risk ratio or odds ratio, respectively.
<br>
<br>



##### Assumptions and Diagnostics
Key part of causal analyses is evaluating the underlying causal assumptions in order to form a judgement about to what extent the estimated effects can be interpreted as being causal. In this part it is crucial to think through why the assumptions seem plausible to hold as it helps you justify the causal interpretations. CarefullyCausal discusses five key underlying causal assumptions including: (conditional) exchangeability, consistency, positivity, having a well-specified model and having no measurement errors. In the printed output a brief description and bold statement is provided regarding what you are assuming. This should by no means scare you off, but should motivate you to look into each assumption and to think about arguments why the assumption does indeed seem plausible to hold. We will now look into each assumption in more detail and show what useful diagnostics that are saved in the output may assist you.

```{r Assumptions, eval=FALSE}
#> To interpret these effects as causal, the following key assumptions must be satisfied: 
#> 
#> [1] Conditional exchangeability: implies that adjusting for "race, sex, education, smokeintensity, smokeyrs, wt71, exercise, active, age" is enough to completely eliminate 
#> all confounding and selection bias. See the covariate balance table ($Assumptions$exchangeability$covariate_balance) 
#> in the saved output and the corresponding explanations ($Assumptions$exchangeability$explanation). 
#> 
#> [2] Positivity: is satisfied when both exposed and unexposed individuals are observed within every stratum of variables adjusted for ( race, sex, education, smokeintensity, smokeyrs, wt71, exercise, active, age ). This can be evaluated using the propensity plots saved in the output at $Assumptions$positivity$plots (or identically use the ps.plot() function), the table below ($Assumptions$positivity$ps_table) and the corresponding explanation found at $Assumptions$positivity$explanation. Note: PS=propensity score 
#>  
#>                        PS range for 1
#> observed exposure: 0   0.0338, 0.6520
#> observed exposure: 1   0.0685, 0.7709
#> 
#> [3] Consistency: implies that exposure 'qsmk' must be sufficiently well-defined so that any variation within 
#> the definition of the exposure would not result in a different outcome. See $Assumption$consistency 
#> for a more in-depth explanation and examples. 
#> 
#> [4] No measurement error: assumes that all variables were measured without substantial error, such that
#> no substantial measurement bias is present. However, if the presence of substantial measurement bias is plausible, 
#> then the estimated effects should be carefully reconsidered as being causal effects. See $Assumptions$no_measurement_error 
#> for a further discussion 
#> 
#> [5] Well-specified models: assumes that any models used are well-specified meaning that they include all
#> relevant non-linearities and/or statistical interactions

```
<br>

###### Conditional Exchangeability
We can obtain a more detailed explanation and interpretation of the exchangeability assumption from the saved output object.
```{r Exchangeability Assumptions, eval=FALSE}
# We can obtain an explanation/interpretation from the saved output object named "output"
output$Assumptions$exchangeability$explanation

#> [1] "Conditional exchangeability implies the absence of any confounding or selection bias after adjusting
#> for:  race, sex, education, smokeintensity, smokeyrs, wt71, exercise, active, age . In other words, the
#> exposed group is a perfect representation what would have happened to the unexposed group had they been
#> exposed (and vice versa). The covariate balancing table and corresponding balance plots in the output can
#> be consulted ($Assumptions$exchangeability$covariate_balance) where better balance between the two
#> groups will indicate less residual bias due to the variables adjusted for. Any confounding due to
#> variables not adjusted for will remain. Besides checking the covariate balance of the current adjusted
#> covariates, an important reflective question to be thought-over is: given the current adjusted for
#> covariates, are there any other important (unmeasured) covariates that affect both treatment
#> assignment and outcome of interest that should be adjusted for without inducing collider or
#> selection bias? Next to this conditional setting, we can also have a setting when no covariates
#> are adjusted for and we assume marginal exchangeability. Marginal exchangeability implies the
#> absence of any confounding or selection bias when not adjusting for anything (unconditionally).
#> This is obtained in an ideal randomized experiment design"
```
<br>

```{r CVB1 Exchangeability Assumptions, eval=FALSE}
# We can obtain covariate balance table from the saved output object named "output"
output$Assumptions$exchangeability$covariate_balance
```


```{r CVB2 Exchangeability Assumptions, eval=TRUE,echo=FALSE}
# We can obtain an explanation/interpretation from the saved output object named "output"
knitr::kable(output$Assumptions$exchangeability$covariate_balance$Balance, caption = "Balance Measures")
knitr::kable(output$Assumptions$exchangeability$covariate_balance$Observations, caption = "Effective Sample Size")
```
<br>

We can obtain covariate balance plots in the same way as before, so from the saved output object named "output". Below we will show just two plots, but in the output you can find two *overall* balance plots where one is in terms of *standardized mean difference* (shown below) and the other is in terms of *absolute standardized mean differences*. In addition, there is a balance plot per covariate (an example is shown for the variable sex). The terms *unadjusted* and *adjusted* refer to before weighting and after weighting, respectively, using the estimated weights from the `CBPS` function and package. Ideally, we would like to see balancing covariates such that the difference between the means is close to zero. However, it should be noted that only variables are balanced that are adjusted for and thus we might still have residual confounding if we miss important confounders.
```{r CVB3 Exchangeability Assumptions, eval=FALSE}
# We can obtain covariate balance plots from the saved output object named "output"
output$Assumptions$exchangeability$balance_plots$Covariate_balance_std
output$Assumptions$exchangeability$balance_plots$sex

```


```{r CVB4 Exchangeability Assumptions, eval=TRUE, echo=FALSE, fig.show='hold',out.width='50%'}
output$Assumptions$exchangeability$balance_plots$Covariate_balance_std
output$Assumptions$exchangeability$balance_plots$sex

```
<br>



###### Positivity
Just as with the exchangeability, we can obtain a more detailed explanation and interpretation of the positivity assumption from the saved output object.
```{r Posivity Assumptions, eval=FALSE}
# We can obtain an explanation/interpretation from the saved output object named "output"
output$Assumptions$positivity

#> [1] "Positivity requires that there are both exposed and unexposed individuals within every strata of: race,
#> sex, education, smokeintensity, smokeyrs, wt71, exercise, active, age. More formally, positivity is
#> satisfied if for every combination of confounders: 'race, sex, education, smokeintensity, smokeyrs, wt71,
#> exercise, active, age' the probability of receiving exposure 'qsmk' is 0<Pr(qsmk)<1. The conditional
#> probability of receiving exposure 'qsmk' when conditioning on covariates 'race, sex, education,
#> smokeintensity, smokeyrs, wt71, exercise, active, age' is referred to as propensity score (PS). Hence,
#> the propensity score ranges table shows the minimum and maximum value of the estimated conditional
#> probabilities and should not equal 0 or 1,as that would violate positivity since there could be a
#> deterministic assignment of exposure. In addition, the ps.plot() function can be used to generate a
#> propensity score plot and can be used to evaluate the complete distribution of the estimated PS.
#> This PS plot can be used to look for ranges of the PS where there is no overlap between exposed
#> and unexposed, in terms of the propensity scores. The ranges table should be used in conjuction
#> with the PS plot."


```
<br>

To get a better idea of potential positivity violations we can obtain a propensity score plot. This plots the conditional probability density plots of the propensity score. 
```{r Ps plot1 Positivity Assumptions, eval=FALSE}
# We can obtain covariate balance plots from the saved output object named "output"
output$Assumptions$positivity$plots[[1]]

```

<center>
```{r Ps plot2 Positivity Assumptions, eval=TRUE, echo=FALSE, fig.show='hold',out.width='50%', fig.align='center'}
output$Assumptions$positivity$plots[[1]]

```
</center>
<br>









